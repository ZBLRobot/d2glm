# BERT模型的架构

我们不再赘述“:ref:`chapter-2`”中描述的Transformer模型的构建模块。在本节中，我们将重点关注BERT模型的与原始Transformer中不同的地方。

我们重点关注[Devlin等人（2018年）](https://arxiv.org/pdf/1810.04805.pdf)这篇论文中设计的改进版编码器。我们首先将介绍编码器的架构，然后介绍预训练输入环境的准备工作。然后我们将描述BERT的两步骤框架：预训练和微调。

